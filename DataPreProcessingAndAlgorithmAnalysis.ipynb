{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecoupledDataProcessingAndAlgorithmAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN/JfB8Ehh1O86HHdy8RPlb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanishkad123/Covid19Visualization/blob/master/DataPreProcessingAndAlgorithmAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARjWEakjrwbP"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtGUIh5MsA5V"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P92T9C7ho8a5",
        "outputId": "2ec3c29a-5260-41a6-94c8-bf46c9d0a04e"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLpUw430sRrA"
      },
      "source": [
        "Work on AI data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq8sVk8nsLuC"
      },
      "source": [
        "df = pd.read_csv(\"/content/AI Export.csv\",sep=\",\", encoding='cp1252')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWLLnQTzsaeS"
      },
      "source": [
        "Work on FI data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEJoeLmssN3Q"
      },
      "source": [
        "#df = pd.read_csv(\"/content/drive/MyDrive/Capstone/Data/FI.csv\",header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ3ZXsnfspNz"
      },
      "source": [
        "AC_MODEL = CRJ700"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMyXhzmpsoQE"
      },
      "source": [
        "df = df[df['AC_MODEL']=='CRJ700']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnIHC3Nns3Ez"
      },
      "source": [
        "df['features'] = df['INTERRUPTION_REASON'].str.cat(df['CORRECTIVE_ACTION'], sep='  ',na_rep=' ')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU1-tLjkttvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a18f31-8ad0-4f01-eb4d-c556ddd6038b"
      },
      "source": [
        "import re\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "stemmer = PorterStemmer()\r\n",
        "def identify_tokens1(df):\r\n",
        "    comment = df['features']\r\n",
        "    comment = re.sub(r'\\d',' ',comment)\r\n",
        "    words = nltk.word_tokenize(comment)\r\n",
        "    new_words = [stemmer.stem(word) for word in words]\r\n",
        "    comment = ' '.join(new_words)\r\n",
        "    return comment\r\n",
        "df['features_1'] = df.apply(identify_tokens1, axis=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoHv09sng9ic"
      },
      "source": [
        "df['features_1'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXUf0zXZie1t"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "vectorizer = TfidfVectorizer(max_features=40000,stop_words='english')\r\n",
        "testb = vectorizer.fit_transform(df['features_1'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIu0pEXMfYRC"
      },
      "source": [
        "#Check weights of tokens inside vectorizer\r\n",
        "vect_score = np.asarray(testb.mean(axis=0)).ravel().tolist()\r\n",
        "vect_array = pd.DataFrame({'term': vectorizer.get_feature_names(), 'weight': vect_score})\r\n",
        "vect_array.sort_values(by='weight',ascending=False,inplace=True)\r\n",
        "vect_array.to_csv('tfidfWeights_withoutDigits_PorterStemmer.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REk3_HL5XDyb"
      },
      "source": [
        "#Check frequency of tokens inside vectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "vectorizer = TfidfVectorizer(max_features=40000,stop_words='english').fit(df['features_1'])\r\n",
        "vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfJJswwguRjp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X = df['features_1']\r\n",
        "y = df['ATA_CAUSE']\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmCWrd5jj1dT",
        "outputId": "e04c8894-f9b0-408f-c16a-5f533bd7d1dc"
      },
      "source": [
        "testb.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25696, 17800)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOZwInw8kACG",
        "outputId": "afd9c846-e275-4cd4-b108-e246cdecd68e"
      },
      "source": [
        "testb[10,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x15816 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 7 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_NwsehtpgSv",
        "outputId": "28f7a3c5-bd50-4fab-dd28-a9b6e6c51fd5"
      },
      "source": [
        "ros = RandomOverSampler()\r\n",
        "X_over_sampled, Y_over_sampled = ros.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjPrAyPpuv3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5b106d8-f169-4ca5-9fde-baea4b7bd881"
      },
      "source": [
        "X_over_sampled.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1862112, 17800)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOVmxpqbqiUp",
        "outputId": "0b446615-1adb-4ce8-bbe2-2704cb4c4191"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\r\n",
        "clf = make_pipeline(LinearSVC())\r\n",
        "clf.fit(X_over_sampled, Y_over_sampled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('linearsvc',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftlAVrIpD7_v"
      },
      "source": [
        "clfpredicted = clf.predict(X_test)\r\n",
        "print(metrics.accuracy_score(y_test, clfpredicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqOm5-Mdbpve"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF3LpzHKwfB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce16c40-7265-4523-dd02-7fd2393ef079"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.calibration import CalibratedClassifierCV\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn import metrics\r\n",
        "\r\n",
        "pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=40000,stop_words='english')),('clf',CalibratedClassifierCV(LinearSVC()))])\r\n",
        "# pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('clf', LogisticRegression())])\r\n",
        "# pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('clf', KNeighborsClassifier())])\r\n",
        "# pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('clf', DecisionTreeClassifier())])\r\n",
        "# pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('clf', SVC())])\r\n",
        "pipe.fit(X_train,y_train)\r\n",
        "predicted = pipe.predict(X_test)\r\n",
        "print(metrics.accuracy_score(y_test, predicted))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6178988326848249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NQeRYaHIv7m",
        "outputId": "5495ab78-7013-452b-db20-517191202e21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predicted[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "261701"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8aoAB-1JsAM",
        "outputId": "8ad4873d-cc0a-45f1-de88-04107ab6faea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "#probs = pipe.predict_proba(X_test)\r\n",
        "#best_n = np.argsort(-probs, axis = 1)[3:] \r\n",
        "b = pd.DataFrame(pipe.predict_proba([identify_tokens1({'features':'# 2 GEN Found Oil TEMP Bulb wire off'})]), columns=pipe.classes_)\r\n",
        "#b = np.argsort(pipe.classes_, pipe.predict_proba([identify_tokens1({'features':'# 2 GEN Found Oil TEMP Bulb wire off'})])[0])\r\n",
        "b.sort_values(by=0,axis=1,ascending=False).iloc[:, 0:3]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>7931</th>\n",
              "      <th>2411</th>\n",
              "      <th>200</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.300073</td>\n",
              "      <td>0.072749</td>\n",
              "      <td>0.060404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       7931      2411      200 \n",
              "0  0.300073  0.072749  0.060404"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlK8iDqObEFs"
      },
      "source": [
        "pipe.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wZ_dzwk4cNS"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "pipelines = []\r\n",
        "pipelines.append(('ScaledLR', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('LR', LogisticRegression())])))\r\n",
        "pipelines.append(('ScaledLDA', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('LDA', KNeighborsClassifier())])))\r\n",
        "pipelines.append(('ScaledKNN', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('KNN', LogisticRegression())])))\r\n",
        "pipelines.append(('ScaledCART', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('CART', DecisionTreeClassifier())])))\r\n",
        "pipelines.append(('ScaledNB', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('NB', GaussianNB())])))\r\n",
        "pipelines.append(('ScaledSVM', Pipeline([('tfidf',TfidfVectorizer(max_features=4000,stop_words='english')),('SVM', SVC())])))\r\n",
        "\r\n",
        "results = []\r\n",
        "names=[]\r\n",
        "for name, model in pipelines:\r\n",
        "    kfold = KFold(n_splits=10)\r\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\r\n",
        "    results.append(cv_results)\r\n",
        "    names.append(name)\r\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\r\n",
        "    print(msg)\r\n",
        "\r\n",
        "# Compare Algorithms\r\n",
        "fig = plt.figure()\r\n",
        "fig.suptitle('Algorithm Comparison')\r\n",
        "ax = fig.add_subplot(111)\r\n",
        "plt.boxplot(results)\r\n",
        "ax.set_xticklabels(names)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-kOWpGp2klA"
      },
      "source": [
        "Use for creating deployment model : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6yhuZhF2q1S",
        "outputId": "d1657269-dfc5-4546-baaa-6b15c91259b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.calibration import CalibratedClassifierCV\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn import metrics\r\n",
        "import pickle\r\n",
        "\r\n",
        "df = pd.read_csv(\"/content/AI Export.csv\",sep=\",\", encoding='cp1252')\r\n",
        "df = df[df['AC_MODEL']=='CRJ700']\r\n",
        "df['features'] = df['INTERRUPTION_REASON'].str.cat(df['CORRECTIVE_ACTION'], sep='  ',na_rep=' ')\r\n",
        "stemmer = PorterStemmer()\r\n",
        "def identify_tokens1(df):\r\n",
        "    comment = df['features']\r\n",
        "    comment = re.sub(r'\\d',' ',comment)\r\n",
        "    words = nltk.word_tokenize(comment)\r\n",
        "    new_words = [stemmer.stem(word) for word in words]\r\n",
        "    comment = ' '.join(new_words)\r\n",
        "    return comment\r\n",
        "df['features_1'] = df.apply(identify_tokens1, axis=1)\r\n",
        "X = df['features_1']\r\n",
        "y = df['ATA_CAUSE']\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "pipe = Pipeline([('tfidf',TfidfVectorizer(max_features=40000,stop_words='english')),('clf',CalibratedClassifierCV(LinearSVC()))])\r\n",
        "pipe.fit(X_train,y_train)\r\n",
        "\r\n",
        "Pkl_Filename = \"linearsvc_model.pkl\"\r\n",
        "with open(Pkl_Filename, 'wb') as file:  \r\n",
        "    pickle.dump(pipe, file)\r\n",
        "print('done')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}